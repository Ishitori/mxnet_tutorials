{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling MXNet Models\n",
    "\n",
    "It is often helpful to understand what operations take how much time in a running a model. This helps optimize the model to run faster. In this tutorial, we will learn how to profile MXNet models to measure their running time and memory consumption using the MXNet profiler.\n",
    "\n",
    "## The incorrect way to profile\n",
    "\n",
    "If you have just begun using MXNet, you might be tempted to measure execution time of your model using Python's `time` module like shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for matrix multiplication: 0.000451 sec\n",
      "\n",
      "[[491.7539  501.33057 498.82922 ... 504.64465 505.7025  494.6814 ]\n",
      " [501.4342  494.96442 508.25684 ... 515.6646  511.40936 505.58218]\n",
      " [504.009   503.47287 502.61414 ... 507.9103  512.05664 498.56577]\n",
      " ...\n",
      " [495.23993 500.00586 497.47757 ... 509.4031  502.84097 499.77383]\n",
      " [490.50592 487.20087 489.2447  ... 498.09854 501.73517 493.34265]\n",
      " [500.73102 510.1065  504.37692 ... 520.82    509.48035 513.1865 ]]\n",
      "Time for printing the output: 0.173924 sec\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from mxnet import autograd, nd\n",
    "import mxnet as mx\n",
    "\n",
    "start = time()\n",
    "x = nd.random_uniform(shape=(2000,2000))\n",
    "y = nd.dot(x, x)\n",
    "print('Time for matrix multiplication: %f sec\\n' % (time() - start))\n",
    "\n",
    "start = time()                                \n",
    "print(y.asnumpy())                                \n",
    "print('Time for printing the output: %f sec' % (time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, it seems as if printing the output takes lot more time that multiplying two large matrices. That doesn't feel right. \n",
    "\n",
    "This is because in MXNet, all operations are executed asynchronously. So, when `nd.dot(x, x)` returns, the matrix multiplication is not complete, it has only been queued for execution. `asnumpy` in `print(y.asnumpy())` however waits for the result to be computed and hence takes longer time.\n",
    "\n",
    "## The correct way to profile\n",
    "\n",
    "The correct way to measure running time of MXNet models is to use MXNet profiler. In the rest of this tutorial, we will learn how to use the MXNet profiler to measure the running time and memory consumption of MXNet models.\n",
    "\n",
    "To use the profiler, you need to build MXNet with `USE_PROFILER` enabled. For example,\n",
    "\n",
    "```\n",
    "make -j $(nproc) USE_OPENCV=1 USE_BLAS=openblas USE_PROFILER=1\n",
    "```\n",
    "\n",
    "Check the [instructions](http://mxnet.incubator.apache.org/install/index.html?device=Linux&language=Python&processor=CPU) for installing from source for more information on building from source. \n",
    "\n",
    "After building with `USE_PROFILER=True` and installing, you can import the profiler and configure it from Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import profiler\n",
    "profiler.set_config(profile_all=True, aggregate_stats=True, filename='profile_output.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`profile_all` enables all types of profiling. You can also individually enable the following types of profiling:\n",
    "\n",
    "- `profile_symbolic` (boolean): whether to profile symbolic operators\n",
    "- `profile_imperative` (boolean): whether to profile imperative operators\n",
    "- `profile_memory` (boolean): whether to profile memory usage\n",
    "- `profile_api` (boolean): whether to profile the C API\n",
    "\n",
    "`aggregate_stats` aggregates statistics in memory which can then be printed to console by calling `profiler.dumps()`.\n",
    "\n",
    "### Setup: Build a model\n",
    "\n",
    "Let's build a small convolutional neural network that we can use for profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "net = gluon.nn.HybridSequential()\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Conv2D(channels=20, kernel_size=5, activation='relu'))\n",
    "    net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n",
    "    net.add(gluon.nn.Conv2D(channels=50, kernel_size=5, activation='relu'))\n",
    "    net.add(gluon.nn.MaxPool2D(pool_size=2, strides=2))\n",
    "    net.add(gluon.nn.Flatten())\n",
    "    net.add(gluon.nn.Dense(512, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need data that we can run through the network for profiling. We'll use the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.data.vision import transforms\n",
    "train_data = gluon.data.DataLoader(gluon.data.vision.MNIST(train=True).transform_first(transforms.ToTensor()),\n",
    "                                   batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a method that will run one training iteration given data and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU is available\n",
    "ctx = mx.gpu() if mx.test_utils.list_gpus() else mx.cpu()\n",
    "\n",
    "# Initialize the parameters with random weights\n",
    "net.collect_params().initialize(mx.init.Xavier(), ctx=ctx)\n",
    "\n",
    "# Use SGD optimizer\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': .1})\n",
    "\n",
    "# Softmax Cross Entropy is a frequently used loss function for multi-classs classification\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "# A helper function to run one training iteration\n",
    "def run_training_iteration(data, label):\n",
    "    \n",
    "    # Load data and label is the right context\n",
    "    data = data.as_in_context(ctx)\n",
    "    label = label.as_in_context(ctx)\n",
    "    \n",
    "    # Run the forward pass\n",
    "    with autograd.record():\n",
    "        output = net(data)\n",
    "        loss = softmax_cross_entropy(output, label)\n",
    "    \n",
    "    # Run the backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Apply changes to parameters\n",
    "    trainer.step(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting and stopping the profiler\n",
    "\n",
    "When the first forward pass is run on a network, MXNet does a number of housekeeping tasks including infering the shapes of various parameters, allocating memory for intermediate and final outputs, etc. For these reasons, profiling the first iteration doesn't provide accurate results. We will therefore skip the first iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the first iteration without profiling\n",
    "itr = iter(train_data)\n",
    "run_training_iteration(*next(itr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run the next iteration with the profiler turned on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data, label = next(itr)\n",
    "\n",
    "# Ask the profiler to start recording\n",
    "profiler.set_state('run')\n",
    "\n",
    "run_training_iteration(*next(itr))\n",
    "\n",
    "# Ask the profiler to stop recording\n",
    "profiler.set_state('stop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between running and stopping the profiler, you can also pause and resume the profiler `profiler.pause()` and `profiler.resume()` respectively to profile only parts of code you want to profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing profiler output\n",
    "\n",
    "There are two ways to view the information collected by the profiler. You can either view it in console or you can view a more graphical version in a browser.\n",
    "\n",
    "#### 1. View in console\n",
    "\n",
    "You can use the `profiler.dumps()` method to view the information collected by the profiler in the console. The collected information contains time taken by each operator, time taken by each C API and memory consumed in both CPU and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Profile Statistics.\n",
      "\tNote that counter items are counter values and not time units.\n",
      "Device Storage\n",
      "=================\n",
      "Name                          Total Count        Time (ms)    Min Time (ms)    Max Time (ms)    Avg Time (ms)\n",
      "----                          -----------        ---------    -------------    -------------    -------------\n",
      "Memory: cpu/0                         264           0.0000           0.0000         401.6640         200.8320\n",
      "Memory: gpu/0                          87       11870.2080         200.7040       12034.3037        5916.7998\n",
      "\n",
      "MXNET_C_API\n",
      "=================\n",
      "Name                          Total Count        Time (ms)    Min Time (ms)    Max Time (ms)    Avg Time (ms)\n",
      "----                          -----------        ---------    -------------    -------------    -------------\n",
      "MXNDArrayReshape64                      2           0.0900           0.0290           0.0610           0.0450\n",
      "MXAutogradBackwardEx                    2           1.3430           0.6180           0.7250           0.6715\n",
      "MXAutogradSetIsTraining                 4           0.0030           0.0000           0.0010           0.0008\n",
      "MXAutogradSetIsRecording                4           0.0020           0.0000           0.0010           0.0005\n",
      "MXNDArraySyncCopyFromCPU                2           0.0950           0.0440           0.0510           0.0475\n",
      "MXNDArrayCreateEx                       6           0.0150           0.0010           0.0050           0.0025\n",
      "MXNDArrayGetDType                       6           0.0030           0.0000           0.0010           0.0005\n",
      "MXNDArrayFree                         292           0.9960           0.0000           0.0250           0.0034\n",
      "MXNDArraySetGradState                  16           0.0110           0.0000           0.0010           0.0007\n",
      "MXNDArrayGetGradState                  16           0.0090           0.0000           0.0010           0.0006\n",
      "MXNDArrayGetContext                   156           0.0710           0.0000           0.0010           0.0005\n",
      "MXNet C API Calls                     948           0.9480           0.0010           0.9480           0.4735\n",
      "MXNet C API Concurrency              1896           0.0000           0.0000           0.0010           0.0005\n",
      "MXNDArrayGetShape                     138           0.0770           0.0000           0.0010           0.0006\n",
      "MXNDArrayAt                           128           0.2160           0.0010           0.0030           0.0017\n",
      "MXImperativeInvokeEx                  176           4.7190           0.0140           0.1230           0.0268\n",
      "\n",
      "operator\n",
      "=================\n",
      "Name                          Total Count        Time (ms)    Min Time (ms)    Max Time (ms)    Avg Time (ms)\n",
      "----                          -----------        ---------    -------------    -------------    -------------\n",
      "_backward_Pooling                       2           0.4210           0.2090           0.2120           0.2105\n",
      "_backward_copy                          4           0.2950           0.0670           0.0800           0.0737\n",
      "sgd_update                             16           1.2950           0.0250           0.1550           0.0809\n",
      "_backward_Activation                    4           0.1760           0.0400           0.0480           0.0440\n",
      "_backward_mean                          4           0.2300           0.0450           0.0700           0.0575\n",
      "Convolution                             8           3.0450           0.2960           0.4600           0.3806\n",
      "stack                                   4           0.2970           0.0630           0.0860           0.0742\n",
      "pick                                    4           0.1230           0.0300           0.0320           0.0308\n",
      "WaitForVar                              4           0.0330           0.0060           0.0100           0.0082\n",
      "Activation                             12           0.6470           0.0290           0.0860           0.0539\n",
      "mean                                    4           0.1970           0.0430           0.0550           0.0492\n",
      "_image_to_tensor                      256           1.8800           0.0040           0.0250           0.0073\n",
      "_backward_pick                          4           0.1630           0.0380           0.0440           0.0408\n",
      "Pooling                                 8           0.5460           0.0410           0.0960           0.0683\n",
      "_backward_FullyConnected                8           1.1680           0.0780           0.2710           0.1460\n",
      "DeleteVariable                        336           0.7150           0.0010           0.0140           0.0021\n",
      "_mul_scalar                             4           0.1070           0.0250           0.0290           0.0268\n",
      "CopyCPU2GPU                             8           0.6910           0.0480           0.1270           0.0864\n",
      "FullyConnected                          8           1.4210           0.1340           0.2160           0.1776\n",
      "SetValueOp                              4           0.2570           0.0530           0.0760           0.0642\n",
      "log_softmax                             4           0.1440           0.0350           0.0370           0.0360\n",
      "_backward_mul_scalar                    4           0.1290           0.0300           0.0350           0.0322\n",
      "_backward_log_softmax                   4           0.6480           0.0400           0.2840           0.1620\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(profiler.dumps())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. View in browser\n",
    "\n",
    "You can also dump the information collected by the profiler into a `json` file using the `profiler.dump()` function and view it in a browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiler.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dump()` creates a `json` file which can be viewed using a trace consumer like `chrome://tracing` in the Chrome browser. Here is a snapshot that shows the output of the profiling we did above.\n",
    "\n",
    "![Tracing Screenshot](profiler_output_chrome.png)\n",
    "\n",
    "Let's zoom in to check the time taken by operators\n",
    "\n",
    "![Operator profiling](profile_operators.png)\n",
    "\n",
    "The above picture visualizes the sequence in which the operators were executed and the time taken by each operator.\n",
    "\n",
    "If you would like to learn more about the profiler, there are more examples available [here](https://github.com/apache/incubator-mxnet/tree/master/example/profiler)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
