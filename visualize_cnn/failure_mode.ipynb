{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from cnnviz import cnnviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mxnet.gluon.model_zoo import model_store\n",
    "\n",
    "from mxnet.initializer import Xavier\n",
    "from mxnet.gluon.nn import MaxPool2D, Flatten, Dense, Dropout, BatchNorm\n",
    "from cnnviz.layers import Activation, Conv2D\n",
    "\n",
    "class VGG(mx.gluon.HybridBlock):\n",
    "    def __init__(self, layers, filters, classes=1000, batch_norm=False, **kwargs):\n",
    "        super(VGG, self).__init__(**kwargs)\n",
    "        assert len(layers) == len(filters)\n",
    "        with self.name_scope():\n",
    "            self.features = self._make_features(layers, filters, batch_norm)\n",
    "            self.features.add(Dense(4096, activation='relu',\n",
    "                                       weight_initializer='normal',\n",
    "                                       bias_initializer='zeros'))\n",
    "            self.features.add(Dropout(rate=0.5))\n",
    "            self.features.add(Dense(4096, activation='relu',\n",
    "                                       weight_initializer='normal',\n",
    "                                       bias_initializer='zeros'))\n",
    "            self.features.add(Dropout(rate=0.5))\n",
    "            self.output = Dense(classes,\n",
    "                                   weight_initializer='normal',\n",
    "                                   bias_initializer='zeros')\n",
    "\n",
    "    def _make_features(self, layers, filters, batch_norm):\n",
    "        featurizer = mx.gluon.nn.HybridSequential(prefix='')\n",
    "        for i, num in enumerate(layers):\n",
    "            for _ in range(num):\n",
    "                featurizer.add(Conv2D(filters[i], kernel_size=3, padding=1,\n",
    "                                         weight_initializer=Xavier(rnd_type='gaussian',\n",
    "                                                                   factor_type='out',\n",
    "                                                                   magnitude=2),\n",
    "                                         bias_initializer='zeros'))\n",
    "                if batch_norm:\n",
    "                    featurizer.add(BatchNorm())\n",
    "                featurizer.add(Activation('relu'))\n",
    "            featurizer.add(MaxPool2D(strides=2))\n",
    "        return featurizer\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.features(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "    \n",
    "vgg_spec = {11: ([1, 1, 2, 2, 2], [64, 128, 256, 512, 512]),\n",
    "            13: ([2, 2, 2, 2, 2], [64, 128, 256, 512, 512]),\n",
    "            16: ([2, 2, 3, 3, 3], [64, 128, 256, 512, 512]),\n",
    "            19: ([2, 2, 4, 4, 4], [64, 128, 256, 512, 512])}\n",
    "\n",
    "def get_vgg(num_layers, pretrained=False, ctx=mx.cpu(),\n",
    "            root=os.path.join('~', '.mxnet', 'models'), **kwargs):\n",
    "    layers, filters = vgg_spec[num_layers]\n",
    "    net = VGG(layers, filters, **kwargs)\n",
    "    if pretrained:\n",
    "        from mxnet.gluon.model_zoo.model_store import get_model_file\n",
    "        batch_norm_suffix = '_bn' if kwargs.get('batch_norm') else ''\n",
    "        net.load_params(get_model_file('vgg%d%s'%(num_layers, batch_norm_suffix),\n",
    "                                       root=root), ctx=ctx)\n",
    "    return net\n",
    "\n",
    "def vgg16(**kwargs):\n",
    "    return get_vgg(16, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sz = (224, 224)\n",
    "\n",
    "def preprocess(data):\n",
    "    data = mx.image.imresize(data, image_sz[0], image_sz[1])\n",
    "    data = data.astype(np.float32)\n",
    "    data = data/255\n",
    "    data = mx.image.color_normalize(data,\n",
    "                                    mean=mx.nd.array([0.485, 0.456, 0.406]),\n",
    "                                    std=mx.nd.array([0.229, 0.224, 0.225]))\n",
    "    data = mx.nd.transpose(data, (2,0,1))\n",
    "    return data\n",
    "\n",
    "network = vgg16(pretrained=True, ctx=mx.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(img_path):\n",
    "    with open(img_path, 'rb') as fp:\n",
    "        str_image = fp.read()\n",
    "\n",
    "    #print(str_image)\n",
    "    image = mx.img.imdecode(str_image)\n",
    "    image = preprocess(image)\n",
    "    image = image.expand_dims(axis=0)\n",
    "    #image = image.as_in_context(mx.gpu())\n",
    "\n",
    "    out = network(image)\n",
    "    return out.argmax(axis=1).asnumpy()[0].astype(int)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(10000):\n",
    "#     inference(\"img/snake.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synset = []\n",
    "with open('synset.txt', 'r') as f:\n",
    "    clsnames = [l.rstrip().split(' ', 1)[1].split(',')[0] for l in f]\n",
    "    \n",
    "with open('synset.txt', 'r') as f:\n",
    "    clsnums = [l.rstrip().split(' ', 1)[0] for l in f]\n",
    "\n",
    "clsindices = {}\n",
    "for i, cn in enumerate(clsnums):\n",
    "    clsindices[cn] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsindices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/ssd2/base'\n",
    "train_dir = \"%s/train\" % base_dir\n",
    "\n",
    "for d in os.listdir(train_dir):\n",
    "    img_dir = \"%s/%s/images\" % (train_dir, d)\n",
    "    expected_cls_indx = clsindices[d]\n",
    "    for img_name in os.listdir(img_dir):\n",
    "        img_path = \"%s/%s\" % (img_dir, img_name)\n",
    "        #print(img_path)\n",
    "        infer_cls_indx = inference(img_path)\n",
    "        if expected_cls_indx != infer_cls_indx:\n",
    "            print(\"%s: Expected: %s, Inferred: %s\" % (img_path, clsnames[expected_cls_indx], clsnames[infer_cls_indx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
